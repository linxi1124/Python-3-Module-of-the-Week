{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing Messages to Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with threads, a common use pattern for multiple processes is to divide a job up among several workers to run in parallel. Effective use of multiple processes usually requires some communication between them, so that work can be divided and results can be aggregated. A simple way to communicate between processes with multiprocessing is to use a Queue to pass messages back and forth. **Any object that can be serialized with pickle can pass through a Queue.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing something fancy in Process-2 for Fancy Dan!\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "\n",
    "class MyFancyClass:\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def do_something(self):\n",
    "        proc_name = multiprocessing.current_process().name\n",
    "        print('Doing something fancy in {} for {}!'.format(\n",
    "            proc_name, self.name))\n",
    "\n",
    "\n",
    "def worker(q):\n",
    "    obj = q.get()\n",
    "    obj.do_something()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    queue = multiprocessing.Queue()\n",
    "\n",
    "    p = multiprocessing.Process(target=worker, args=(queue,))\n",
    "    p.start()\n",
    "\n",
    "    queue.put(MyFancyClass('Fancy Dan'))\n",
    "\n",
    "    # Wait for the worker to finish\n",
    "    queue.close()\n",
    "    queue.join_thread()\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more complex example shows how to manage several workers consuming data from a JoinableQueue and passing results back to the parent process. The poison pill technique is used to stop the workers. After setting up the real tasks, the main program adds one “stop” value per worker to the job queue. When a worker encounters the special value, it breaks out of its processing loop. The main process uses the task queue’s join() method to wait for all of the tasks to finish before processing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 16 consumers\n",
      "Consumer-5: 2 * 2\n",
      "Consumer-3: 0 * 0\n",
      "Consumer-6: 3 * 3\n",
      "Consumer-8: 5 * 5\n",
      "Consumer-9: 6 * 6\n",
      "Consumer-4: 1 * 1\n",
      "Consumer-11: 8 * 8\n",
      "Consumer-18: 4 * 4\n",
      "Consumer-16: Exiting\n",
      "Consumer-12: 9 * 9\n",
      "Consumer-17: Exiting\n",
      "Consumer-7: 7 * 7\n",
      "Consumer-14: Exiting\n",
      "Consumer-15: Exiting\n",
      "Consumer-10: Exiting\n",
      "Consumer-13: Exiting\n",
      "Consumer-3: Exiting\n",
      "Consumer-5: Exiting\n",
      "Consumer-6: Exiting\n",
      "Consumer-11: Exiting\n",
      "Consumer-8: Exiting\n",
      "Consumer-9: Exiting\n",
      "Consumer-4: Exiting\n",
      "Consumer-12: Exiting\n",
      "Consumer-18: Exiting\n",
      "Consumer-7: Exiting\n",
      "Result: 0 * 0 = 0\n",
      "Result: 2 * 2 = 4\n",
      "Result: 8 * 8 = 64\n",
      "Result: 3 * 3 = 9\n",
      "Result: 6 * 6 = 36\n",
      "Result: 5 * 5 = 25\n",
      "Result: 1 * 1 = 1\n",
      "Result: 9 * 9 = 81\n",
      "Result: 4 * 4 = 16\n",
      "Result: 7 * 7 = 49\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "\n",
    "class Consumer(multiprocessing.Process):\n",
    "\n",
    "    def __init__(self, task_queue, result_queue):\n",
    "        multiprocessing.Process.__init__(self)\n",
    "        self.task_queue = task_queue\n",
    "        self.result_queue = result_queue\n",
    "\n",
    "    def run(self):\n",
    "        proc_name = self.name\n",
    "        while True:\n",
    "            next_task = self.task_queue.get()\n",
    "            if next_task is None:\n",
    "                # Poison pill means shutdown\n",
    "                print('{}: Exiting'.format(proc_name))\n",
    "                self.task_queue.task_done()\n",
    "                break\n",
    "            print('{}: {}'.format(proc_name, next_task))\n",
    "            answer = next_task()\n",
    "            self.task_queue.task_done()\n",
    "            self.result_queue.put(answer)\n",
    "\n",
    "\n",
    "class Task:\n",
    "\n",
    "    def __init__(self, a, b):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "\n",
    "    def __call__(self):\n",
    "        time.sleep(0.1)  # pretend to take time to do the work\n",
    "        return '{self.a} * {self.b} = {product}'.format(\n",
    "            self=self, product=self.a * self.b)\n",
    "\n",
    "    def __str__(self):\n",
    "        return '{self.a} * {self.b}'.format(self=self)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Establish communication queues\n",
    "    tasks = multiprocessing.JoinableQueue()\n",
    "    results = multiprocessing.Queue()\n",
    "\n",
    "    # Start consumers\n",
    "    num_consumers = multiprocessing.cpu_count() * 2\n",
    "    print('Creating {} consumers'.format(num_consumers))\n",
    "    consumers = [\n",
    "        Consumer(tasks, results)\n",
    "        for i in range(num_consumers)\n",
    "    ]\n",
    "    for w in consumers:\n",
    "        w.start()\n",
    "\n",
    "    # Enqueue jobs\n",
    "    num_jobs = 10\n",
    "    for i in range(num_jobs):\n",
    "        tasks.put(Task(i, i))\n",
    "\n",
    "    # Add a poison pill for each consumer\n",
    "    for i in range(num_consumers):\n",
    "        tasks.put(None)\n",
    "\n",
    "    # Wait for all of the tasks to finish\n",
    "    tasks.join()\n",
    "\n",
    "    # Start printing results\n",
    "    while num_jobs:\n",
    "        result = results.get()\n",
    "        print('Result:', result)\n",
    "        num_jobs -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signaling between Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Event class provides a simple way to communicate state information between processes. An event can be toggled between set and unset states. Users of the event object can wait for it to change from unset to set, using an optional timeout value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait_for_event: starting\n",
      "wait_for_event_timeout: starting\n",
      "main: waiting before calling Event.set()\n",
      "wait_for_event_timeout: e.is_set()-> False\n",
      "main: event is set\n",
      "wait_for_event: e.is_set()-> True\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "\n",
    "def wait_for_event(e):\n",
    "    \"\"\"Wait for the event to be set before doing anything\"\"\"\n",
    "    print('wait_for_event: starting')\n",
    "    e.wait()\n",
    "    print('wait_for_event: e.is_set()->', e.is_set())\n",
    "\n",
    "\n",
    "def wait_for_event_timeout(e, t):\n",
    "    \"\"\"Wait t seconds and then timeout\"\"\"\n",
    "    print('wait_for_event_timeout: starting')\n",
    "    e.wait(t)\n",
    "    print('wait_for_event_timeout: e.is_set()->', e.is_set())\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    e = multiprocessing.Event()\n",
    "    w1 = multiprocessing.Process(\n",
    "        name='block',\n",
    "        target=wait_for_event,\n",
    "        args=(e,),\n",
    "    )\n",
    "    w1.start()\n",
    "\n",
    "    w2 = multiprocessing.Process(\n",
    "        name='nonblock',\n",
    "        target=wait_for_event_timeout,\n",
    "        args=(e, 2),\n",
    "    )\n",
    "    w2.start()\n",
    "\n",
    "    print('main: waiting before calling Event.set()')\n",
    "    time.sleep(3)\n",
    "    e.set()\n",
    "    print('main: event is set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When wait() times out it returns without an error. The caller is responsible for checking the state of the event using is_set()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlling Access to Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In situations when a single resource needs to be shared between multiple processes, a Lock can be used to avoid conflicting accesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lock acquired via with\n",
      "Lock acquired directly\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import sys\n",
    "\n",
    "\n",
    "def worker_with(lock, stream):\n",
    "    with lock:\n",
    "        stream.write('Lock acquired via with\\n')\n",
    "\n",
    "\n",
    "def worker_no_with(lock, stream):\n",
    "    lock.acquire()\n",
    "    try:\n",
    "        stream.write('Lock acquired directly\\n')\n",
    "    finally:\n",
    "        lock.release()\n",
    "\n",
    "\n",
    "lock = multiprocessing.Lock()\n",
    "w = multiprocessing.Process(\n",
    "    target=worker_with,\n",
    "    args=(lock, sys.stdout),\n",
    ")\n",
    "nw = multiprocessing.Process(\n",
    "    target=worker_no_with,\n",
    "    args=(lock, sys.stdout),\n",
    ")\n",
    "\n",
    "w.start()\n",
    "nw.start()\n",
    "\n",
    "w.join()\n",
    "nw.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synchronizing Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Condition objects can be used to synchronize parts of a workflow so that some run in parallel but others run sequentially, even if they are in separate processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting stage_2[1]\n",
      "Starting stage_2[2]\n",
      "Starting s1\n",
      "s1 done and ready for stage 2\n",
      "stage_2[2] running\n",
      "stage_2[1] running\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "\n",
    "def stage_1(cond):\n",
    "    \"\"\"perform first stage of work,\n",
    "    then notify stage_2 to continue\n",
    "    \"\"\"\n",
    "    name = multiprocessing.current_process().name\n",
    "    print('Starting', name)\n",
    "    with cond:\n",
    "        print('{} done and ready for stage 2'.format(name))\n",
    "        cond.notify_all()\n",
    "\n",
    "\n",
    "def stage_2(cond):\n",
    "    \"\"\"wait for the condition telling us stage_1 is done\"\"\"\n",
    "    name = multiprocessing.current_process().name\n",
    "    print('Starting', name)\n",
    "    with cond:\n",
    "        cond.wait()\n",
    "        print('{} running'.format(name))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    condition = multiprocessing.Condition()\n",
    "    s1 = multiprocessing.Process(name='s1',\n",
    "                                 target=stage_1,\n",
    "                                 args=(condition,))\n",
    "    s2_clients = [\n",
    "        multiprocessing.Process(\n",
    "            name='stage_2[{}]'.format(i),\n",
    "            target=stage_2,\n",
    "            args=(condition,),\n",
    "        )\n",
    "        for i in range(1, 3)\n",
    "    ]\n",
    "\n",
    "    for c in s2_clients:\n",
    "        c.start()\n",
    "        time.sleep(1)\n",
    "    s1.start()\n",
    "\n",
    "    s1.join()\n",
    "    for c in s2_clients:\n",
    "        c.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, two process run the second stage of a job in parallel, but only after the first stage is done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlling Concurrent Access to Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it is useful to allow more than one worker access to a resource at a time, while still limiting the overall number. For example, a connection pool might support a fixed number of simultaneous connections, or a network application might support a fixed number of concurrent downloads. A Semaphore is one way to manage those connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activating 0 now running ['0']\n",
      "Activating 1 now running ['0', '1']\n",
      "Activating 2 now running ['0', '1', '2']\n",
      "Activating 3 now running ['1', '2', '3']\n",
      "Now running ['1', '2', '3']\n",
      "Now running ['1', '2', '3']\n",
      "Activating 4 now running ['1', '2', '4']\n",
      "Now running ['1', '2', '3']\n",
      "Now running ['1', '2', '3']\n",
      "Activating 5 now running ['1', '4', '5']\n",
      "Now running ['1', '4', '5']\n",
      "Now running ['1', '4', '5']\n",
      "Activating 6 now running ['1', '5', '6']\n",
      "Activating 7 now running ['1', '6', '7']\n",
      "Now running ['1', '4', '5']\n",
      "Now running ['1', '6', '7']\n",
      "Activating 8 now running ['6', '7', '8']\n",
      "Activating 9 now running ['7', '8', '9']\n",
      "Now running ['1', '6', '7']\n",
      "Now running ['6', '7', '8']\n",
      "Now running ['7', '8', '9']\n",
      "Now running ['7', '8', '9']\n",
      "Now running ['7', '8', '9']\n",
      "Now running ['7', '8', '9']\n",
      "Now running ['7', '8', '9']\n",
      "Now running ['7', '8', '9']\n",
      "Now running ['8', '9']\n",
      "Now running ['9']\n",
      "Now running ['9']\n",
      "Now running ['9']\n",
      "Now running []\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "\n",
    "class ActivePool:\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ActivePool, self).__init__()\n",
    "        self.mgr = multiprocessing.Manager()\n",
    "        self.active = self.mgr.list()\n",
    "        self.lock = multiprocessing.Lock()\n",
    "\n",
    "    def makeActive(self, name):\n",
    "        with self.lock:\n",
    "            self.active.append(name)\n",
    "\n",
    "    def makeInactive(self, name):\n",
    "        with self.lock:\n",
    "            self.active.remove(name)\n",
    "\n",
    "    def __str__(self):\n",
    "        with self.lock:\n",
    "            return str(self.active)\n",
    "\n",
    "\n",
    "def worker(s, pool):\n",
    "    name = multiprocessing.current_process().name\n",
    "    with s:\n",
    "        pool.makeActive(name)\n",
    "        print('Activating {} now running {}'.format(\n",
    "            name, pool))\n",
    "        time.sleep(random.random())\n",
    "        pool.makeInactive(name)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pool = ActivePool()\n",
    "    s = multiprocessing.Semaphore(3)\n",
    "    jobs = [\n",
    "        multiprocessing.Process(\n",
    "            target=worker,\n",
    "            name=str(i),\n",
    "            args=(s, pool),\n",
    "        )\n",
    "        for i in range(10)\n",
    "    ]\n",
    "\n",
    "    for j in jobs:\n",
    "        j.start()\n",
    "\n",
    "    while True:\n",
    "        alive = 0\n",
    "        for j in jobs:\n",
    "            if j.is_alive():\n",
    "                alive += 1\n",
    "                j.join(timeout=0.1)\n",
    "                print('Now running {}'.format(pool))\n",
    "        if alive == 0:\n",
    "            # all done\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing Shared State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous example, the list of active processes is maintained centrally in the ActivePool instance via a special type of list object created by a Manager. The Manager is responsible for coordinating shared information state between all of its users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: {0: 0, 1: 2, 3: 6, 2: 4, 4: 8, 5: 10, 6: 12, 7: 14, 8: 16, 9: 18}\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import pprint\n",
    "\n",
    "\n",
    "def worker(d, key, value):\n",
    "    d[key] = value\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mgr = multiprocessing.Manager()\n",
    "    d = mgr.dict()\n",
    "    jobs = [\n",
    "        multiprocessing.Process(\n",
    "            target=worker,\n",
    "            args=(d, i, i * 2),\n",
    "        )\n",
    "        for i in range(10)\n",
    "    ]\n",
    "    for j in jobs:\n",
    "        j.start()\n",
    "    for j in jobs:\n",
    "        j.join()\n",
    "    print('Results:', d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By creating the list through the manager, it is shared and updates are seen in all processes. Dictionaries are also supported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared Namespaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to dictionaries and lists, a Manager can create a shared Namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before event, error: 'Namespace' object has no attribute 'value'\n",
      "After event: This is the value\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "\n",
    "def producer(ns, event):\n",
    "    ns.value = 'This is the value'\n",
    "    event.set()\n",
    "\n",
    "\n",
    "def consumer(ns, event):\n",
    "    try:\n",
    "        print('Before event: {}'.format(ns.value))\n",
    "    except Exception as err:\n",
    "        print('Before event, error:', str(err))\n",
    "    event.wait()\n",
    "    print('After event:', ns.value)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mgr = multiprocessing.Manager()\n",
    "    namespace = mgr.Namespace()\n",
    "    event = multiprocessing.Event()\n",
    "    p = multiprocessing.Process(\n",
    "        target=producer,\n",
    "        args=(namespace, event),\n",
    "    )\n",
    "    c = multiprocessing.Process(\n",
    "        target=consumer,\n",
    "        args=(namespace, event),\n",
    "    )\n",
    "\n",
    "    c.start()\n",
    "    p.start()\n",
    "\n",
    "    c.join()\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any named value added to the Namespace is visible to all of the clients that receive the Namespace instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It is important to know that updates to the contents of mutable values in the namespace are not propagated automatically.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before event: []\n",
      "After event : []\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "\n",
    "def producer(ns, event):\n",
    "    # DOES NOT UPDATE GLOBAL VALUE!\n",
    "    ns.my_list.append('This is the value')\n",
    "    event.set()\n",
    "\n",
    "\n",
    "def consumer(ns, event):\n",
    "    print('Before event:', ns.my_list)\n",
    "    event.wait()\n",
    "    print('After event :', ns.my_list)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mgr = multiprocessing.Manager()\n",
    "    namespace = mgr.Namespace()\n",
    "    namespace.my_list = []\n",
    "\n",
    "    event = multiprocessing.Event()\n",
    "    p = multiprocessing.Process(\n",
    "        target=producer,\n",
    "        args=(namespace, event),\n",
    "    )\n",
    "    c = multiprocessing.Process(\n",
    "        target=consumer,\n",
    "        args=(namespace, event),\n",
    "    )\n",
    "\n",
    "    c.start()\n",
    "    p.start()\n",
    "\n",
    "    c.join()\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Pools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pool class can be used to manage a fixed number of workers for simple cases where the work to be done can be broken up and distributed between workers independently. The return values from the jobs are collected and returned as a list. The pool arguments include the number of processes and a function to run when starting the task process (invoked once per child)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input   : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Built-in: [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
      "Starting ForkPoolWorker-87\n",
      "Starting ForkPoolWorker-86\n",
      "Starting ForkPoolWorker-85\n",
      "Starting ForkPoolWorker-88\n",
      "Starting ForkPoolWorker-89\n",
      "Starting ForkPoolWorker-90\n",
      "Starting ForkPoolWorker-91\n",
      "Starting ForkPoolWorker-92\n",
      "Starting ForkPoolWorker-93\n",
      "Starting ForkPoolWorker-94\n",
      "Starting ForkPoolWorker-95\n",
      "Starting ForkPoolWorker-96\n",
      "Starting ForkPoolWorker-97\n",
      "Starting ForkPoolWorker-98\n",
      "Starting ForkPoolWorker-100\n",
      "Starting ForkPoolWorker-99\n",
      "Pool    : [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "\n",
    "def do_calculation(data):\n",
    "    return data * 2\n",
    "\n",
    "\n",
    "def start_process():\n",
    "    print('Starting', multiprocessing.current_process().name)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    inputs = list(range(10))\n",
    "    print('Input   :', inputs)\n",
    "\n",
    "    builtin_outputs = map(do_calculation, inputs)\n",
    "    print('Built-in:', [i for i in builtin_outputs])\n",
    "\n",
    "    pool_size = multiprocessing.cpu_count() * 2\n",
    "    pool = multiprocessing.Pool(\n",
    "        processes=pool_size,\n",
    "        initializer=start_process,\n",
    "    )\n",
    "    pool_outputs = pool.map(do_calculation, inputs)\n",
    "    pool.close()  # no more tasks\n",
    "    pool.join()  # wrap up current tasks\n",
    "\n",
    "    print('Pool    :', pool_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Pool creates a fixed number of worker processes and passes jobs to them until there are no more jobs. Setting the maxtasksperchild parameter tells the pool to restart a worker process after it has finished a few tasks, preventing long-running workers from consuming ever more system resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input   : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Built-in: <map object at 0x7f430c35dbe0>\n",
      "Starting ForkPoolWorker-101\n",
      "Starting ForkPoolWorker-102\n",
      "Starting ForkPoolWorker-103\n",
      "Starting ForkPoolWorker-104\n",
      "Starting ForkPoolWorker-105\n",
      "Starting ForkPoolWorker-106\n",
      "Starting ForkPoolWorker-107\n",
      "Starting ForkPoolWorker-108\n",
      "Starting ForkPoolWorker-109\n",
      "Starting ForkPoolWorker-110\n",
      "Starting ForkPoolWorker-111\n",
      "Starting ForkPoolWorker-112\n",
      "Starting ForkPoolWorker-113\n",
      "Starting ForkPoolWorker-114\n",
      "Starting ForkPoolWorker-115\n",
      "Starting ForkPoolWorker-116\n",
      "Pool    : [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "\n",
    "def do_calculation(data):\n",
    "    return data * 2\n",
    "\n",
    "\n",
    "def start_process():\n",
    "    print('Starting', multiprocessing.current_process().name)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    inputs = list(range(10))\n",
    "    print('Input   :', inputs)\n",
    "\n",
    "    builtin_outputs = map(do_calculation, inputs)\n",
    "    print('Built-in:', builtin_outputs)\n",
    "\n",
    "    pool_size = multiprocessing.cpu_count() * 2\n",
    "    pool = multiprocessing.Pool(\n",
    "        processes=pool_size,\n",
    "        initializer=start_process,\n",
    "        maxtasksperchild=2,\n",
    "    )\n",
    "    pool_outputs = pool.map(do_calculation, inputs)\n",
    "    pool.close()  # no more tasks\n",
    "    pool.join()  # wrap up current tasks\n",
    "\n",
    "    print('Pool    :', pool_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pool restarts the workers when they have completed their allotted tasks, even if there is no more work. In this output, eight workers are created, even though there are only 10 tasks, and each worker can complete two of them at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
