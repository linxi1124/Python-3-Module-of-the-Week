{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "* Provide Thread-Safe FIFO Implementation\n",
    "* multi-producer, multi-consumer queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic FIFO Queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Queue class implements a basic first-in, first-out container. Element are added to one \"end\" of the sequence using `put()`, and removed from the other using `get()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = queue.Queue()\n",
    "\n",
    "for i in range(5):\n",
    "    q.put(i)\n",
    "    \n",
    "while not q.empty():\n",
    "    print(q.get(), end=' ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example uses a single thread to illustrate that elements are removed from the queue in the same order in which they are inserted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIFO Queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to the standard FIFO implementation of Queue, the LifoQueue uses last-in, first-out ordering (normally associated with a stack data structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import queue\n",
    "\n",
    "q = queue.LifoQueue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    q.put(i)\n",
    "    \n",
    "while not q.empty():\n",
    "    print(q.get(), end=' ')\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priority Queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the processing order of the items in a queue needs to be based on characteristics of those items, rather than just the order they are created or added to the queue. For example, print jobs from the payroll department may take precedence over a code listing that a developer wants to print. PriorityQueue uses the sort order of the contents of the queue to decide which item to retrieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import queue\n",
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "@functools.total_ordering\n",
    "class Job:\n",
    "\n",
    "    def __init__(self, priority, description):\n",
    "        self.priority = priority\n",
    "        self.description = description\n",
    "        print('New job:', description)\n",
    "        return\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        try:\n",
    "            return self.priority == other.priority\n",
    "        except AttributeError:\n",
    "            return NotImplemented\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        try:\n",
    "            return self.priority < other.priority\n",
    "        except AttributeError:\n",
    "            return NotImplemented\n",
    "        \n",
    "q = queue.PriorityQueue()\n",
    "\n",
    "q.put(Job(3, 'Mid-level job'))\n",
    "q.put(Job(10, 'Low-level job'))\n",
    "q.put(Job(1, 'Important job'))\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "def process_job(q):\n",
    "    while True:\n",
    "        next_job = q.get()\n",
    "        print('Processing job:', next_job.description)\n",
    "        q.task_done()\n",
    "\n",
    "\n",
    "workers = [\n",
    "    threading.Thread(target=process_job, args=(q,)),\n",
    "#      threading.Thread(target=process_job, args=(q,)),\n",
    "]\n",
    "for w in workers:\n",
    "    w.setDaemon(True)\n",
    "    w.start()\n",
    "\n",
    "q.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example has multiple threads consuming the jobs, which are processed based on the priority of items in the queue at the time get() was called. The order of processing for items added to the queue while the consumer threads are running depends on thread context switching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Threaded Podcast Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load fetch_podcasts.py\n",
    "# First, some operating parameters are established. \n",
    "# Usually, these would come from user inputs \n",
    "# (e.g., preferences or a database). The example uses hard-coded \n",
    "# values for the number of threads and list of URLs to fetch.\n",
    "\n",
    "from queue import Queue\n",
    "import threading\n",
    "import time\n",
    "import urllib\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import feedparser\n",
    "\n",
    "# Set up some global variables\n",
    "num_fetch_threads = 2\n",
    "enclosure_queue = Queue()\n",
    "\n",
    "# A real app wouldn't use hard-coded data...\n",
    "feed_urls = [\n",
    "    'http://talkpython.fm/episodes/rss',\n",
    "]\n",
    "\n",
    "\n",
    "def message(s):\n",
    "    print('{}: {}'.format(threading.current_thread().name, s))\n",
    "\n",
    "# The function download_enclosures() runs in the worker thread \n",
    "# and processes the downloads using urllib.    \n",
    " \n",
    "def download_enclosures(q):\n",
    "    \"\"\"This is the worker thread function.\n",
    "    It processes items in the queue one after\n",
    "    another.  These daemon threads go into an\n",
    "    infinite loop, and exit only when\n",
    "    the main thread ends.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        message('looking for the next enclosure')\n",
    "        url = q.get()\n",
    "        filename = url.rpartition('/')[-1]\n",
    "        message('downloading {}'.format(filename))\n",
    "        response = urllib.request.urlopen(url)\n",
    "        data = response.read()\n",
    "        # Save the downloaded file to the current directory\n",
    "        message('writing to {}'.format(filename))\n",
    "        with open(filename, 'wb') as outfile:\n",
    "            outfile.write(data)\n",
    "        q.task_done()\n",
    "\n",
    "# Set up some threads to fetch the enclosures\n",
    "for i in range(num_fetch_threads):\n",
    "    worker = threading.Thread(\n",
    "        target=download_enclosures,\n",
    "        args=(enclosure_queue,),\n",
    "        name='worker-{}'.format(i),\n",
    "    )\n",
    "    worker.setDaemon(True)\n",
    "    worker.start()\n",
    "    \n",
    "\n",
    "# Download the feed(s) and put the enclosure URLs into\n",
    "# the queue.\n",
    "for url in feed_urls:\n",
    "    response = feedparser.parse(url, agent='fetch_podcasts.py')\n",
    "    for entry in response['entries'][:5]:\n",
    "        for enclosure in entry.get('enclosures', []):\n",
    "            parsed_url = urlparse(enclosure['url'])\n",
    "            message('queuing {}'.format(\n",
    "                parsed_url.path.rpartition('/')[-1]))\n",
    "            enclosure_queue.put(enclosure['url'])\n",
    "\n",
    "# Now wait for the queue to be empty, indicating that we have\n",
    "# processed all of the downloads.\n",
    "message('*** main thread waiting')\n",
    "enclosure_queue.join()\n",
    "message('*** done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker-0: looking for the next enclosure\n",
      "worker-1: looking for the next enclosure\n",
      "worker-1: writing to 10-books-python-developers-should-be-reading.mp3\n",
      "worker-1: looking for the next enclosure\n",
      "MainThread: *** main thread waiting\n",
      "MainThread: *** done\n"
     ]
    }
   ],
   "source": [
    "!python fetch_podcasts.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove all download files\n",
    "!rm *.mp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join and task_done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Queue.task_done` and `Queue.join` is used closely:\n",
    "\n",
    "* When you call `join`, the thread call it will block untile all item in the queue have been gotten and processed.\n",
    "\n",
    "* The count of unfinised tasks goes up whenever an item is added to the queue.\n",
    "\n",
    "* The count goes down whenever a consumer call `task_done` to indicate that the item was retrived and all work on it is complete. When the count of unfinised tasks drops to zero, `join` unblocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
