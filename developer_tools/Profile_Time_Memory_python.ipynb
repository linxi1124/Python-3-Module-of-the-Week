<<<<<<< Updated upstream:developer_tools/Profile_Time_Memory_python.ipynb
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile Time\n",
    "[Timeit(for small piece of code)](#timeit)\n",
    "\n",
    "[cProfile(function level statistic)](#CProfile)\n",
    "\n",
    "[line_profiler(line level profiling)](#line_profiler)\n",
    "\n",
    "# Profile Memory\n",
    "[memory_profiler(function and line level)](#memory_profiler)\n",
    "\n",
    "[profile object reference: objgraph](#objgraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"timeit\"></a>\n",
    "## Timeit(for small piece of code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Python comes with a module called timeit. You can use it to time small code snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run it on command line interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```\n",
    "python -m timeit -s \"[ord(x) for x in 'abcdfghi']\"\n",
    "\n",
    ">#100000000 loops, best of 3: 0.0115 usec per loop\n",
    "\n",
    "python -m timeit -s \"[chr(int(x)) for x in '123456789']\"\n",
    "\n",
    ">#python -m timeit -s \"[chr(int(x)) for x in '123456789']\"\n",
    "100000000 loops, best of 3: 0.0119 usec per loop\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A multi-line statement may be given by specifying each line as a separate statement argument; indented lines are possible by enclosing an argument in quotes and using leading spaces. Multiple -s options are treated similarly.\n",
    "\n",
    "If -n is not given, a suitable number of loops is calculated by trying successive powers of 10 until the total time is at least 0.2 seconds.\n",
    "\n",
    "default_timer() measurements can be affected by other programs running on the same machine, so the best thing to do when accurate timing is necessary is to repeat the timing a few times and use the best time. The -r option is good for this; the default of 3 repetitions is probably enough in most cases. You can use time.process_time() to measure CPU time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import timeit for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3263827509999828\n"
     ]
    }
   ],
   "source": [
    "def my_function():\n",
    "    try:\n",
    "        1 / 0\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    import timeit\n",
    "    setup = \"from __main__ import my_function\"\n",
    "    print(timeit.timeit(\"my_function()\", setup=setup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter notebook magic command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 8.26 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000000 loops, best of 3: 312 ns per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit my_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"CProfile\"></a>\n",
    "## CProfile(function level statistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python comes with its own code profilers built-in. There is the profile module and the cProfile module. The profile module is pure Python, but it will add a lot of overhead to anything you profile, so itâ€™s usually recommended that you go with cProfile, which has a similar interface but is much faster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### profile a script on command line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate profile file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python -m cProfile [-o output_file] [-s sort_order] myscript.py```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### analyze output profile file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pstats\n",
    "p = pstats.Stats('profiledata001.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 25 08:03:10 2017    profiledata001.txt\n",
      "\n",
      "         1830996407 function calls (1830976655 primitive calls) in 2867.918 seconds\n",
      "\n",
      "   Random listing order was used\n",
      "   List reduced from 2451 to 25 due to restriction <0.01>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\http\\client.py:1337(CannotSendRequest)\n",
      "        7    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\dateutil\\parser.py:298(_convert)\n",
      "        7    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\numpy\\compat\\_inspect.py:144(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\pandas\\core\\computation\\ops.py:32(UndefinedVariableError)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\numpy\\core\\arrayprint.py:711(IntegerFormat)\n",
      "      932    0.109    0.000    0.109    0.000 {method 'isidentifier' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:491(_MergeOperation)\n",
      "        1    0.000    0.000    0.001    0.001 E:\\python\\lib\\site-packages\\six.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\ctypes\\wintypes.py:155(WIN32_FIND_DATAW)\n",
      "        1    0.000    0.000    0.001    0.001 E:\\python\\lib\\site-packages\\pandas\\core\\dtypes\\dtypes.py:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\pandas\\core\\config.py:223(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\pickle.py:219(_Unframer)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\pandas\\tseries\\offsets.py:1009(<listcomp>)\n",
      "        1    0.000    0.000    0.006    0.006 E:\\python\\lib\\email\\utils.py:5(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\unittest\\suite.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\dateutil\\relativedelta.py:18(relativedelta)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\json\\encoder.py:67(JSONEncoder)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:5(DefragResult)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\urllib\\parse.py:243(SplitResult)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\pandas\\io\\formats\\format.py:298(EastAsianTextAdjustment)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\pandas\\util\\_validators.py:4(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\email\\feedparser.py:44(BufferedSubFile)\n",
      "      163    0.000    0.000    0.000    0.000 E:\\python\\lib\\socket.py:75(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\numpy\\core\\_internal.py:671(TooHardError)\n",
      "        1    0.000    0.000    0.001    0.001 E:\\python\\lib\\difflib.py:27(<module>)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f69644a3be0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print profile\n",
    "p.print_stats(0.01) # check reference for parameter, 0.01 mean only print 1% of output, because complete log is too long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meaning of Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ncalls\n",
    "    * for the number of calls.\n",
    "* tottime\n",
    "    * for the total time spent in the given function (and excluding time made in calls to sub-functions)\n",
    "* percall\n",
    "    * is the quotient of tottime divided by ncalls\n",
    "* cumtime\n",
    "    * is the cumulative time spent in this and all subfunctions (from invocation till exit). This figure is accurate even for recursive functions.\n",
    "* percall\n",
    "    * is the quotient of cumtime divided by primitive calls\n",
    "* filename:lineno(function)\n",
    "    * provides the respective data of each function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### you can sort output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f69644a3be0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.sort_stats(\"cumtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 25 08:03:10 2017    profiledata001.txt\n",
      "\n",
      "         1830996407 function calls (1830976655 primitive calls) in 2867.918 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 2451 to 25 due to restriction <0.01>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "    427/1    0.116    0.000 2867.919 2867.919 {built-in method exec}\n",
      "        1    0.107    0.107 2867.819 2867.819 run.py:1(<module>)\n",
      "        1    0.709    0.709 2862.906 2862.906 run.py:9(start_analyze_log)\n",
      "      188    0.090    0.000 2079.355   11.060 E:\\python\\lib\\site-packages\\bs4\\__init__.py:87(__init__)\n",
      "      188    1.064    0.006 2078.857   11.058 E:\\python\\lib\\site-packages\\bs4\\__init__.py:285(_feed)\n",
      "      188  207.396    1.103 2077.793   11.052 E:\\python\\lib\\site-packages\\bs4\\builder\\_lxml.py:121(feed)\n",
      "      104    1.180    0.011 1684.802   16.200 E:\\data\\burdenoff\\dataanalysis\\adkutility.py:20(adk_test_type)\n",
      " 26358783  287.394    0.000 1053.401    0.000 E:\\python\\lib\\site-packages\\bs4\\builder\\_lxml.py:145(start)\n",
      "       12    0.001    0.000  700.330   58.361 E:\\data\\burdenoff\\dataanalysis\\s3standby.py:41(s3standby_analyze_to_db)\n",
      "       12    0.677    0.056  624.435   52.036 E:\\data\\burdenoff\\dataanalysis\\s3standby.py:8(S3_Standby)\n",
      " 26358783  126.567    0.000  603.223    0.000 E:\\python\\lib\\site-packages\\bs4\\builder\\_lxml.py:194(end)\n",
      " 26358783   61.671    0.000  591.798    0.000 E:\\python\\lib\\site-packages\\bs4\\__init__.py:447(handle_starttag)\n",
      " 79076537  183.151    0.000  579.789    0.000 E:\\python\\lib\\site-packages\\bs4\\__init__.py:337(endData)\n",
      "   772111    1.478    0.000  523.556    0.001 E:\\python\\lib\\site-packages\\bs4\\element.py:1298(find_all)\n",
      "   772111    5.226    0.000  522.078    0.001 E:\\python\\lib\\site-packages\\bs4\\element.py:518(_find_all)\n",
      "   772111    6.870    0.000  482.632    0.001 E:\\python\\lib\\site-packages\\bs4\\element.py:1801(__init__)\n",
      "   288448  122.510    0.000  475.762    0.002 E:\\python\\lib\\site-packages\\bs4\\element.py:543(<genexpr>)\n",
      "117121588  339.989    0.000  340.531    0.000 E:\\python\\lib\\site-packages\\bs4\\element.py:1323(descendants)\n",
      "       11    0.000    0.000  232.160   21.105 E:\\data\\burdenoff\\dataanalysis\\faststarup.py:91(faststartup_analyze_to_db)\n",
      "       11    0.830    0.075  227.804   20.709 E:\\data\\burdenoff\\dataanalysis\\faststarup.py:15(analyzefaststartupfile)\n",
      " 52614596   76.026    0.000  223.218    0.000 E:\\python\\lib\\site-packages\\bs4\\__init__.py:367(object_was_parsed)\n",
      "131588163  197.993    0.000  201.233    0.000 E:\\python\\lib\\site-packages\\bs4\\element.py:203(setup)\n",
      "      147    0.007    0.000  196.189    1.335 E:\\data\\burdenoff\\dataanalysis\\model.py:190(update_testresult)\n",
      "      140    0.192    0.001  195.298    1.395 E:\\data\\burdenoff\\dataanalysis\\adkutility.py:51(update_db_helper)\n",
      " 26358971  143.175    0.000  192.338    0.000 E:\\python\\lib\\site-packages\\bs4\\element.py:813(__init__)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f69644a3be0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.print_stats(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### you can also add resttriction when print states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 25 08:03:10 2017    profiledata001.txt\n",
      "\n",
      "         1830996407 function calls (1830976655 primitive calls) in 2867.918 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 2451 to 50 due to restriction <'dataanalysis'>\n",
      "   List reduced from 50 to 5 due to restriction <0.1>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      104    1.180    0.011 1684.802   16.200 E:\\data\\burdenoff\\dataanalysis\\adkutility.py:20(adk_test_type)\n",
      "       12    0.001    0.000  700.330   58.361 E:\\data\\burdenoff\\dataanalysis\\s3standby.py:41(s3standby_analyze_to_db)\n",
      "       12    0.677    0.056  624.435   52.036 E:\\data\\burdenoff\\dataanalysis\\s3standby.py:8(S3_Standby)\n",
      "       11    0.000    0.000  232.160   21.105 E:\\data\\burdenoff\\dataanalysis\\faststarup.py:91(faststartup_analyze_to_db)\n",
      "       11    0.830    0.075  227.804   20.709 E:\\data\\burdenoff\\dataanalysis\\faststarup.py:15(analyzefaststartupfile)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f69644a3be0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# my only scipt in in this path: E:\\data\\burdenoff\\dataanalysis, so I can only print analysis on my own code\n",
    "# it can help to find the issue more faster\n",
    "p.print_stats(\"dataanalysis\",0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### other thing you can do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[official documents](https://docs.python.org/3.5/library/profile.html#the-python-profilers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"line_profiler\"></a>\n",
    "## line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* this is a 3rd party package install with: ***pip install line_profiler***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually use the line_profiler, we will need some code to profile. But first, I need to explain how line_profiler works when you call it on the command line. You will actually be calling line_profiler by calling the kernprof script. I thought that was a bit confusing the first time I used it, but thatâ€™s just the way it works. Hereâ€™s the normal way to use it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```kernprof -l silly_functions.py```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when it finishes: Wrote profile results to silly_functions.py.lprof(filename.lprof). This is a binary file that we canâ€™t view directly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note**:\n",
    " next few cell run be run under terminal, don't run it in notebok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run kernprof though, it will actually inject an instance of LineProfiler into your scriptâ€™s __builtins__ namespace. The instance will be named profile and is meant to be used as a decorator. With that in mind, we can actually write our script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# silly_functions.py\n",
    "import time\n",
    " \n",
    "@profile\n",
    "def fast_function():\n",
    "    print(\"I'm a fast function!\")\n",
    " \n",
    "@profile\n",
    "def slow_function():\n",
    "    time.sleep(2)\n",
    "    print(\"I'm a slow function\")\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    fast_function()\n",
    "    slow_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### view the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "commandï¼špython -m line_profiler script_to_profile.py.lprof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I'm a fast function!\n",
    "# I'm a slow function\n",
    "# Wrote profile results to silly_functions.py.lprof\n",
    "# Timer unit: 1e-06 s\n",
    " \n",
    "# Total time: 3.4e-05 s\n",
    "# File: silly_functions.py\n",
    "# Function: fast_function at line 3\n",
    " \n",
    "# Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "# ==============================================================\n",
    "#      3                                           @profile\n",
    "#      4                                           def fast_function():\n",
    "#      5         1           34     34.0    100.0      print(\"I'm a fast function!\")\n",
    " \n",
    "# Total time: 2.001 s\n",
    "# File: silly_functions.py\n",
    "# Function: slow_function at line 7\n",
    " \n",
    "# Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "# ==============================================================\n",
    "#      7                                           @profile\n",
    "#      8                                           def slow_function():\n",
    "#      9         1      2000942 2000942.0    100.0      time.sleep(2)\n",
    "#     10         1           59     59.0      0.0      print(\"I'm a slow function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that the source code is printed out with the timing information for each line. There are six columns of information here. Letâ€™s find out what each one means.\n",
    "\n",
    "    Line # â€“ The line number of the code that was profiled\n",
    "    Hits â€“ The number of times that particular line was executed\n",
    "    Time â€“ The total amount of time the line took to execute (in the timerâ€™s unit). The timer unit can be seen at the beginning of the output\n",
    "    Per Hit â€“ The average amount of time that line of code took to execute (in timer units)\n",
    "    % Time â€“ The percentage of time spent on the line relative to the total amount of time spent in said function\n",
    "    Line Contents â€“ The actual source code that was executed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notebook magic: %lprun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you happen to be an IPython user, then you might want to know that IPython has a magic command (%lprun) that allows you to specify functions to profile and even which statement to execute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"memory_profiler\"></a>\n",
    "## memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another great 3rd party profiling package is memory_profiler. The memory_profiler module can be used for monitoring memory consumption in a process or you can use it for a line-by-line analysis of the memory consumption of your code. Since itâ€™s not included with Python, weâ€™ll have to install it. You can use pip for this:\n",
    "\n",
    "\n",
    "```pip install memory_profiler```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once itâ€™s installed, we need some code to run it against. The memory_profiler actually works in much the same way as line_profiler in that when you run it, memory_profiler will inject an instance of itself into __builtins__ named profile that you are supposed to use as a decorator on the function you are profiling. Hereâ€™s a simple example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  command line usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* command:  python -m memory_profiler example.py\n",
    "* you need add function decorator for function you want to profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from memory_profiler import profile\n",
    "\n",
    "@profile\n",
    "def my_func():\n",
    "    a = [1] * (10 ** 6)\n",
    "    b = [2] * (2 * 10 ** 7)\n",
    "    del b\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-based memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it is useful to have full memory usage reports as a function of time (not line-by-line) of external processes (be it Python scripts or not). In this case the executable mprof might be useful. Use it like:\n",
    "\n",
    "command:    \n",
    "mprof run <executable>    \n",
    "mprof plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** note***:\n",
    "1. my preferred way of runing it is:    \n",
    "mprof run xxx | tee $(date + \"%Y_%m_%d_%I_%M_%p\").log\n",
    "\n",
    "in this way, we can keep both picture and text analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"objgraph\"></a>\n",
    "## objgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup\n",
    "**Note**:\n",
    "don't forget to install `graphviz` and `xdot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
=======
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile Time\n",
    "[Timeit(for small piece of code)](#timeit)\n",
    "\n",
    "[cProfile(function level statistic)](#CProfile)\n",
    "\n",
    "[line_profiler(line level profiling)](#line_profiler)\n",
    "\n",
    "# Profile Memory\n",
    "[memory_profiler(function and line level)](#memory_profiler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"timeit\"></a>\n",
    "## Timeit(for small piece of code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Python comes with a module called timeit. You can use it to time small code snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run it on command line interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```\n",
    "python -m timeit -s \"[ord(x) for x in 'abcdfghi']\"\n",
    "\n",
    ">#100000000 loops, best of 3: 0.0115 usec per loop\n",
    "\n",
    "python -m timeit -s \"[chr(int(x)) for x in '123456789']\"\n",
    "\n",
    ">#python -m timeit -s \"[chr(int(x)) for x in '123456789']\"\n",
    "100000000 loops, best of 3: 0.0119 usec per loop\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A multi-line statement may be given by specifying each line as a separate statement argument; indented lines are possible by enclosing an argument in quotes and using leading spaces. Multiple -s options are treated similarly.\n",
    "\n",
    "If -n is not given, a suitable number of loops is calculated by trying successive powers of 10 until the total time is at least 0.2 seconds.\n",
    "\n",
    "default_timer() measurements can be affected by other programs running on the same machine, so the best thing to do when accurate timing is necessary is to repeat the timing a few times and use the best time. The -r option is good for this; the default of 3 repetitions is probably enough in most cases. You can use time.process_time() to measure CPU time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import timeit for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3263827509999828\n"
     ]
    }
   ],
   "source": [
    "def my_function():\n",
    "    try:\n",
    "        1 / 0\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    import timeit\n",
    "    setup = \"from __main__ import my_function\"\n",
    "    print(timeit.timeit(\"my_function()\", setup=setup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter notebook magic command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 8.26 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000000 loops, best of 3: 312 ns per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit my_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"CProfile\"></a>\n",
    "## CProfile(function level statistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python comes with its own code profilers built-in. There is the profile module and the cProfile module. The profile module is pure Python, but it will add a lot of overhead to anything you profile, so itâ€™s usually recommended that you go with cProfile, which has a similar interface but is much faster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### profile a script on command line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate profile file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python -m cProfile [-o output_file] [-s sort_order] myscript.py```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### analyze output profile file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pstats\n",
    "p = pstats.Stats('profiledata001.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 25 08:03:10 2017    profiledata001.txt\n",
      "\n",
      "         1830996407 function calls (1830976655 primitive calls) in 2867.918 seconds\n",
      "\n",
      "   Random listing order was used\n",
      "   List reduced from 2451 to 25 due to restriction <0.01>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\http\\client.py:1337(CannotSendRequest)\n",
      "        7    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\dateutil\\parser.py:298(_convert)\n",
      "        7    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\numpy\\compat\\_inspect.py:144(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\pandas\\core\\computation\\ops.py:32(UndefinedVariableError)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\numpy\\core\\arrayprint.py:711(IntegerFormat)\n",
      "      932    0.109    0.000    0.109    0.000 {method 'isidentifier' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:491(_MergeOperation)\n",
      "        1    0.000    0.000    0.001    0.001 E:\\python\\lib\\site-packages\\six.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\ctypes\\wintypes.py:155(WIN32_FIND_DATAW)\n",
      "        1    0.000    0.000    0.001    0.001 E:\\python\\lib\\site-packages\\pandas\\core\\dtypes\\dtypes.py:1(<module>)\n",
      "        2    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\pandas\\core\\config.py:223(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\pickle.py:219(_Unframer)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\pandas\\tseries\\offsets.py:1009(<listcomp>)\n",
      "        1    0.000    0.000    0.006    0.006 E:\\python\\lib\\email\\utils.py:5(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\unittest\\suite.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\dateutil\\relativedelta.py:18(relativedelta)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\json\\encoder.py:67(JSONEncoder)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:5(DefragResult)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\urllib\\parse.py:243(SplitResult)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\pandas\\io\\formats\\format.py:298(EastAsianTextAdjustment)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\pandas\\util\\_validators.py:4(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\email\\feedparser.py:44(BufferedSubFile)\n",
      "      163    0.000    0.000    0.000    0.000 E:\\python\\lib\\socket.py:75(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 E:\\python\\lib\\site-packages\\numpy\\core\\_internal.py:671(TooHardError)\n",
      "        1    0.000    0.000    0.001    0.001 E:\\python\\lib\\difflib.py:27(<module>)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f69644a3be0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print profile\n",
    "p.print_stats(0.01) # check reference for parameter, 0.01 mean only print 1% of output, because complete log is too long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meaning of Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ncalls\n",
    "    * for the number of calls.\n",
    "* tottime\n",
    "    * for the total time spent in the given function (and excluding time made in calls to sub-functions)\n",
    "* percall\n",
    "    * is the quotient of tottime divided by ncalls\n",
    "* cumtime\n",
    "    * is the cumulative time spent in this and all subfunctions (from invocation till exit). This figure is accurate even for recursive functions.\n",
    "* percall\n",
    "    * is the quotient of cumtime divided by primitive calls\n",
    "* filename:lineno(function)\n",
    "    * provides the respective data of each function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### you can sort output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f69644a3be0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.sort_stats(\"cumtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 25 08:03:10 2017    profiledata001.txt\n",
      "\n",
      "         1830996407 function calls (1830976655 primitive calls) in 2867.918 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 2451 to 25 due to restriction <0.01>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "    427/1    0.116    0.000 2867.919 2867.919 {built-in method exec}\n",
      "        1    0.107    0.107 2867.819 2867.819 run.py:1(<module>)\n",
      "        1    0.709    0.709 2862.906 2862.906 run.py:9(start_analyze_log)\n",
      "      188    0.090    0.000 2079.355   11.060 E:\\python\\lib\\site-packages\\bs4\\__init__.py:87(__init__)\n",
      "      188    1.064    0.006 2078.857   11.058 E:\\python\\lib\\site-packages\\bs4\\__init__.py:285(_feed)\n",
      "      188  207.396    1.103 2077.793   11.052 E:\\python\\lib\\site-packages\\bs4\\builder\\_lxml.py:121(feed)\n",
      "      104    1.180    0.011 1684.802   16.200 E:\\data\\burdenoff\\dataanalysis\\adkutility.py:20(adk_test_type)\n",
      " 26358783  287.394    0.000 1053.401    0.000 E:\\python\\lib\\site-packages\\bs4\\builder\\_lxml.py:145(start)\n",
      "       12    0.001    0.000  700.330   58.361 E:\\data\\burdenoff\\dataanalysis\\s3standby.py:41(s3standby_analyze_to_db)\n",
      "       12    0.677    0.056  624.435   52.036 E:\\data\\burdenoff\\dataanalysis\\s3standby.py:8(S3_Standby)\n",
      " 26358783  126.567    0.000  603.223    0.000 E:\\python\\lib\\site-packages\\bs4\\builder\\_lxml.py:194(end)\n",
      " 26358783   61.671    0.000  591.798    0.000 E:\\python\\lib\\site-packages\\bs4\\__init__.py:447(handle_starttag)\n",
      " 79076537  183.151    0.000  579.789    0.000 E:\\python\\lib\\site-packages\\bs4\\__init__.py:337(endData)\n",
      "   772111    1.478    0.000  523.556    0.001 E:\\python\\lib\\site-packages\\bs4\\element.py:1298(find_all)\n",
      "   772111    5.226    0.000  522.078    0.001 E:\\python\\lib\\site-packages\\bs4\\element.py:518(_find_all)\n",
      "   772111    6.870    0.000  482.632    0.001 E:\\python\\lib\\site-packages\\bs4\\element.py:1801(__init__)\n",
      "   288448  122.510    0.000  475.762    0.002 E:\\python\\lib\\site-packages\\bs4\\element.py:543(<genexpr>)\n",
      "117121588  339.989    0.000  340.531    0.000 E:\\python\\lib\\site-packages\\bs4\\element.py:1323(descendants)\n",
      "       11    0.000    0.000  232.160   21.105 E:\\data\\burdenoff\\dataanalysis\\faststarup.py:91(faststartup_analyze_to_db)\n",
      "       11    0.830    0.075  227.804   20.709 E:\\data\\burdenoff\\dataanalysis\\faststarup.py:15(analyzefaststartupfile)\n",
      " 52614596   76.026    0.000  223.218    0.000 E:\\python\\lib\\site-packages\\bs4\\__init__.py:367(object_was_parsed)\n",
      "131588163  197.993    0.000  201.233    0.000 E:\\python\\lib\\site-packages\\bs4\\element.py:203(setup)\n",
      "      147    0.007    0.000  196.189    1.335 E:\\data\\burdenoff\\dataanalysis\\model.py:190(update_testresult)\n",
      "      140    0.192    0.001  195.298    1.395 E:\\data\\burdenoff\\dataanalysis\\adkutility.py:51(update_db_helper)\n",
      " 26358971  143.175    0.000  192.338    0.000 E:\\python\\lib\\site-packages\\bs4\\element.py:813(__init__)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f69644a3be0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.print_stats(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### you can also add resttriction when print states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 25 08:03:10 2017    profiledata001.txt\n",
      "\n",
      "         1830996407 function calls (1830976655 primitive calls) in 2867.918 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 2451 to 50 due to restriction <'dataanalysis'>\n",
      "   List reduced from 50 to 5 due to restriction <0.1>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      104    1.180    0.011 1684.802   16.200 E:\\data\\burdenoff\\dataanalysis\\adkutility.py:20(adk_test_type)\n",
      "       12    0.001    0.000  700.330   58.361 E:\\data\\burdenoff\\dataanalysis\\s3standby.py:41(s3standby_analyze_to_db)\n",
      "       12    0.677    0.056  624.435   52.036 E:\\data\\burdenoff\\dataanalysis\\s3standby.py:8(S3_Standby)\n",
      "       11    0.000    0.000  232.160   21.105 E:\\data\\burdenoff\\dataanalysis\\faststarup.py:91(faststartup_analyze_to_db)\n",
      "       11    0.830    0.075  227.804   20.709 E:\\data\\burdenoff\\dataanalysis\\faststarup.py:15(analyzefaststartupfile)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7f69644a3be0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# my only scipt in in this path: E:\\data\\burdenoff\\dataanalysis, so I can only print analysis on my own code\n",
    "# it can help to find the issue more faster\n",
    "p.print_stats(\"dataanalysis\",0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### other thing you can do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[official documents](https://docs.python.org/3.5/library/profile.html#the-python-profilers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"line_profiler\"></a>\n",
    "## line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* this is a 3rd party package install with: ***pip install line_profiler***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually use the line_profiler, we will need some code to profile. But first, I need to explain how line_profiler works when you call it on the command line. You will actually be calling line_profiler by calling the kernprof script. I thought that was a bit confusing the first time I used it, but thatâ€™s just the way it works. Hereâ€™s the normal way to use it:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```kernprof -l silly_functions.py```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when it finishes: Wrote profile results to silly_functions.py.lprof(filename.lprof). This is a binary file that we canâ€™t view directly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note**:\n",
    " next few cell run be run under terminal, don't run it in notebok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run kernprof though, it will actually inject an instance of LineProfiler into your scriptâ€™s __builtins__ namespace. The instance will be named profile and is meant to be used as a decorator. With that in mind, we can actually write our script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# silly_functions.py\n",
    "import time\n",
    " \n",
    "@profile\n",
    "def fast_function():\n",
    "    print(\"I'm a fast function!\")\n",
    " \n",
    "@profile\n",
    "def slow_function():\n",
    "    time.sleep(2)\n",
    "    print(\"I'm a slow function\")\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    fast_function()\n",
    "    slow_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### view the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "commandï¼špython -m line_profiler script_to_profile.py.lprof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I'm a fast function!\n",
    "# I'm a slow function\n",
    "# Wrote profile results to silly_functions.py.lprof\n",
    "# Timer unit: 1e-06 s\n",
    " \n",
    "# Total time: 3.4e-05 s\n",
    "# File: silly_functions.py\n",
    "# Function: fast_function at line 3\n",
    " \n",
    "# Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "# ==============================================================\n",
    "#      3                                           @profile\n",
    "#      4                                           def fast_function():\n",
    "#      5         1           34     34.0    100.0      print(\"I'm a fast function!\")\n",
    " \n",
    "# Total time: 2.001 s\n",
    "# File: silly_functions.py\n",
    "# Function: slow_function at line 7\n",
    " \n",
    "# Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "# ==============================================================\n",
    "#      7                                           @profile\n",
    "#      8                                           def slow_function():\n",
    "#      9         1      2000942 2000942.0    100.0      time.sleep(2)\n",
    "#     10         1           59     59.0      0.0      print(\"I'm a slow function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that the source code is printed out with the timing information for each line. There are six columns of information here. Letâ€™s find out what each one means.\n",
    "\n",
    "    Line # â€“ The line number of the code that was profiled\n",
    "    Hits â€“ The number of times that particular line was executed\n",
    "    Time â€“ The total amount of time the line took to execute (in the timerâ€™s unit). The timer unit can be seen at the beginning of the output\n",
    "    Per Hit â€“ The average amount of time that line of code took to execute (in timer units)\n",
    "    % Time â€“ The percentage of time spent on the line relative to the total amount of time spent in said function\n",
    "    Line Contents â€“ The actual source code that was executed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notebook magic: %lprun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you happen to be an IPython user, then you might want to know that IPython has a magic command (%lprun) that allows you to specify functions to profile and even which statement to execute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"memory_profiler\"></a>\n",
    "## memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another great 3rd party profiling package is memory_profiler. The memory_profiler module can be used for monitoring memory consumption in a process or you can use it for a line-by-line analysis of the memory consumption of your code. Since itâ€™s not included with Python, weâ€™ll have to install it. You can use pip for this:\n",
    "\n",
    "\n",
    "```pip install memory_profiler```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once itâ€™s installed, we need some code to run it against. The memory_profiler actually works in much the same way as line_profiler in that when you run it, memory_profiler will inject an instance of itself into __builtins__ named profile that you are supposed to use as a decorator on the function you are profiling. Hereâ€™s a simple example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  command line usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* command:  python -m memory_profiler example.py\n",
    "* you need add function decorator for function you want to profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory_profiler import profile\n",
    "\n",
    "@profile\n",
    "def my_func():\n",
    "    a = [1] * (10 ** 6)\n",
    "    b = [2] * (2 * 10 ** 7)\n",
    "    del b\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-based memory usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it is useful to have full memory usage reports as a function of time (not line-by-line) of external processes (be it Python scripts or not). In this case the executable mprof might be useful. Use it like:\n",
    "\n",
    "command:    \n",
    "mprof run <executable>    \n",
    "mprof plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** note***:\n",
    "1. my preferred way of runing it is:    \n",
    "mprof run xxx | tee $(date + \"%Y_%m_%d_%I_%M_%p\").log\n",
    "\n",
    "in this way, we can keep both picture and text analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
>>>>>>> Stashed changes:Profile_Time_Memory_python.ipynb
